{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- convert generated (returns and cond nums) data to usable format to pass to env\n",
    "- check action bound: are actions in [-1,1]?\n",
    "- should we generate 1 long seqence or multiple? how does it effect convergence? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### running from jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for compatible with python 3\n",
    "from __future__ import print_function\n",
    "import os\n",
    "# os.environ[\"KERAS_BACKEND\"] = \"theano\"\n",
    "import numpy as np\n",
    "from utils.data import read_stock_history, index_to_date, date_to_index, normalize\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/zachariemartin/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from model.ddpg.actor import ActorNetwork\n",
    "from model.ddpg.critic import CriticNetwork\n",
    "from model.ddpg.ddpg import DDPG\n",
    "from model.ddpg.ornstein_uhlenbeck import OrnsteinUhlenbeckActionNoise\n",
    "\n",
    "import numpy as np\n",
    "import tflearn\n",
    "import tensorflow as tf\n",
    "\n",
    "from stock_trading import StockActor, StockCritic, obs_normalizer, get_model_path, get_result_path, \\\n",
    "                          test_model, get_variable_scope, test_model_multiple, convert_R_output\n",
    "    \n",
    "from model.supervised.lstm import StockLSTM\n",
    "from model.supervised.cnn import StockCNN\n",
    "\n",
    "from environment.portfolio import PortfolioEnv, MultiActionPortfolioEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters calculated in R\n",
    "filepath = '/Users/zachariemartin/Desktop/School/Projects/summer2019/2/sum19/'\n",
    "\n",
    "alpha, beta, omega, Q_bar = convert_R_output(coef_path = filepath + 'coef.csv',\\\n",
    "                                                   Q_bar_path = filepath + 'Q_bar.csv', num_assets=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common settings\n",
    "batch_size = 64\n",
    "action_bound = 1.\n",
    "tau = 1e-3\n",
    "\n",
    "models = []\n",
    "model_names = []\n",
    "window_length_lst = [3]\n",
    "predictor_type_lst = ['lstm']\n",
    "use_batch_norm = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'returns_stack' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-90a5931a5e20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m }\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPortfolioEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/School/Projects/summer2019/2/sum19/drl/src/environment/portfolio.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, parameters, steps, epsilon, time_cost, window_length, start_idx, num_assets)\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;31m#                          start_date=sample_start_date)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m         self.sim = PortfolioSim(\n\u001b[1;32m    371\u001b[0m             \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/School/Projects/summer2019/2/sum19/drl/src/environment/portfolio.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, parameters, steps, window_length, start_idx)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;31m# NEW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data generated'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/School/Projects/summer2019/2/sum19/drl/src/environment/portfolio.py\u001b[0m in \u001b[0;36mgenerate_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;31m# return np.concatenate((returns_stack,np.tile(np.asarray(condNum_list),(num_assets,1))[:,:,None]),axis=2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;31m# return returns data, condition number data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mreturns_stack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondNum_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'returns_stack' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# # param dict\n",
    "# parameters = {}\n",
    "\n",
    "# # 10 assets\n",
    "num_assets = 10\n",
    "num_rows_per_asset = 5\n",
    "\n",
    "# # calculated in R\n",
    "# a = 0.007073296\n",
    "# b = 0.658588119\n",
    "\n",
    "# # import from R\n",
    "coef = pd.read_csv(filepath + 'coef.csv')\n",
    "\n",
    "# # mu, ar1, omega, alpha, beta 0,1,2,3,4 for each asset - 5 values for each asset so 500 total values\n",
    "# parameters['alpha'] = np.array([coef.loc[i,'x'] for i in range(3,(num_assets*num_rows_per_asset),5)])\n",
    "# parameters['beta'] = np.array([coef.loc[i,'x'] for i in range(4,(num_assets*num_rows_per_asset),5)])\n",
    "# parameters['omega'] = np.array([coef.loc[i,'x'] for i in range(2,(num_assets*num_rows_per_asset),5)])\n",
    "# parameters['Q_bar'] = pd.read_csv('Q_bar.csv').drop('Unnamed: 0',axis=1).to_numpy()\n",
    "# parameters['H_init'] = pd.read_csv('H_init.csv').drop('Unnamed: 0',axis=1).to_numpy()\n",
    "# parameters['Q'] = pd.read_csv('Q_init.csv').drop('Unnamed: 0',axis=1).to_numpy()\n",
    "# parameters['T'] = 1000\n",
    "# parameters['small_scalar'] = 1e-5\n",
    "# parameters['num_assets'] = 10\n",
    "\n",
    "parameters = {\n",
    "                'alpha' : np.array([coef.loc[i,'x'] for i in range(3,(num_assets*num_rows_per_asset),5)]),\n",
    "                'beta' : np.array([coef.loc[i,'x'] for i in range(4,(num_assets*num_rows_per_asset),5)]),\n",
    "                'omega' : np.array([coef.loc[i,'x'] for i in range(2,(num_assets*num_rows_per_asset),5)]),\n",
    "                'Q_bar' : pd.read_csv(filepath + 'Q_bar.csv').drop('Unnamed: 0',axis=1).to_numpy(),\n",
    "                'H_init' : pd.read_csv(filepath + 'H_init.csv').drop('Unnamed: 0',axis=1).to_numpy(),\n",
    "                'Q' : pd.read_csv(filepath + 'Q_init.csv').drop('Unnamed: 0',axis=1).to_numpy(),\n",
    "                'T' : 1000,\n",
    "                'small_scalar' : 1e-5,\n",
    "                'num_assets' : 10,\n",
    "                # calculated in R - parameters for Q process\n",
    "                'a' : 0.007073296,\n",
    "                'b' : 0.658588119,\n",
    "                'mean' : 100\n",
    "}\n",
    "\n",
    "env = PortfolioEnv(parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = parameters['num_assets'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for window_length in window_length_lst:\n",
    "    for predictor_type in predictor_type_lst:\n",
    "        name = 'DDPG_window_{}_predictor_{}'.format(window_length, predictor_type)\n",
    "        model_names.append(name)\n",
    "        tf.reset_default_graph()\n",
    "        sess = tf.Session()\n",
    "        tflearn.config.init_training_mode()\n",
    "        action_dim = [nb_classes]\n",
    "        state_dim = [nb_classes, window_length]\n",
    "        variable_scope = get_variable_scope(window_length, predictor_type, use_batch_norm)\n",
    "        with tf.variable_scope(variable_scope):\n",
    "            actor = StockActor(sess, state_dim, action_dim, action_bound, 1e-4, tau, batch_size, predictor_type, \n",
    "                               use_batch_norm)\n",
    "            critic = StockCritic(sess=sess, state_dim=state_dim, action_dim=action_dim, tau=1e-3,\n",
    "                                 learning_rate=1e-3, num_actor_vars=actor.get_num_trainable_vars(), \n",
    "                                 predictor_type=predictor_type, use_batch_norm=use_batch_norm)\n",
    "            actor_noise = OrnsteinUhlenbeckActionNoise(mu=np.zeros(action_dim))\n",
    "\n",
    "            model_save_path = get_model_path(window_length, predictor_type, use_batch_norm)\n",
    "            summary_path = get_result_path(window_length, predictor_type, use_batch_norm)\n",
    "\n",
    "            ddpg_model = DDPG(env, sess, actor, critic, actor_noise, obs_normalizer=obs_normalizer,\n",
    "                              config_file='config/stock.json', model_save_path=model_save_path,\n",
    "                              summary_path=summary_path)\n",
    "            ddpg_model.initialize(load_weights=False, verbose=False)\n",
    "            models.append(ddpg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpg_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
