{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# for compatible with python 3\n",
    "from __future__ import print_function\n",
    "import os\n",
    "# os.environ[\"KERAS_BACKEND\"] = \"theano\"\n",
    "import numpy as np\n",
    "from utils.data import read_stock_history, index_to_date, date_to_index, normalize\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1002\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1002\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1002\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1002' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.2.0.min.js\"];\n",
       "  var css_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.css\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1002\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1002\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1002' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.2.0.min.js\"];\n  var css_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.css\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Seaborn, useful for graphics\n",
    "import seaborn as sns\n",
    "\n",
    "# Import Bokeh modules for interactive plotting\n",
    "import bokeh.io\n",
    "#import bokeh.mpl\n",
    "import bokeh.plotting\n",
    "\n",
    "# Magic function to make matplotlib inline; other style specs must come AFTER\n",
    "%matplotlib inline\n",
    "\n",
    "# This enables SVG graphics inline.  There is a bug, so uncomment if it works.\n",
    "# %config InlineBackend.figure_formats = {'svg',}\n",
    "\n",
    "# This enables high resolution PNGs. SVG is preferred, but has problems\n",
    "# rendering vertical and horizontal lines\n",
    "%config InlineBackend.figure_formats = {'png', 'retina'}\n",
    "matplotlib.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rc('legend', fontsize=20)\n",
    "# JB's favorite Seaborn settings for notebooks\n",
    "rc = {'lines.linewidth': 2, \n",
    "      'axes.labelsize': 18, \n",
    "      'axes.titlesize': 18, \n",
    "      'axes.facecolor': 'DFDFE5'}\n",
    "sns.set_context('notebook', rc=rc)\n",
    "sns.set_style('darkgrid', rc=rc)\n",
    "\n",
    "# Set up Bokeh for inline viewing\n",
    "bokeh.io.output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.ddpg.actor import ActorNetwork\n",
    "from model.ddpg.critic import CriticNetwork\n",
    "from model.ddpg.ddpg import DDPG\n",
    "from model.ddpg.ornstein_uhlenbeck import OrnsteinUhlenbeckActionNoise\n",
    "\n",
    "import numpy as np\n",
    "import tflearn\n",
    "import tensorflow as tf\n",
    "\n",
    "from stock_trading import StockActor, StockCritic, obs_normalizer, get_model_path, get_result_path, \\\n",
    "                          test_model, get_variable_scope, test_model_multiple\n",
    "    \n",
    "from model.supervised.lstm import StockLSTM\n",
    "from model.supervised.cnn import StockCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from utils.data import create_target_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "history, abbreviation = read_stock_history('utils/datasets/stocks_history_2.h5')\n",
    "\n",
    "# create new dataset with 100 random stocks from entire dataset\n",
    "random.seed(30)\n",
    "new_list = random.sample(abbreviation,100)\n",
    "\n",
    "create_target_dataset(new_list,filepath='utils/datasets/stocks_history_target3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset for 100 stocks by splitting timestamp\n",
    "history, abbreviation = read_stock_history(filepath='utils/datasets/stocks_history_target3.h5')\n",
    "history = history[:, :, :4]\n",
    "\n",
    "# 100 stocks are all involved. We choose first 3 years as training data\n",
    "num_training_time = 1095\n",
    "target_stocks = abbreviation\n",
    "target_history = np.empty(shape=(len(target_stocks), num_training_time, history.shape[2]))\n",
    "\n",
    "for i, stock in enumerate(target_stocks):\n",
    "    target_history[i] = history[abbreviation.index(stock), :num_training_time, :]\n",
    "\n",
    "# and last 2 years as testing data.\n",
    "testing_stocks = abbreviation\n",
    "testing_history = np.empty(shape=(len(testing_stocks), history.shape[1] - num_training_time, \n",
    "                               history.shape[2]))\n",
    "for i, stock in enumerate(testing_stocks):\n",
    "    testing_history[i] = history[abbreviation.index(stock), num_training_time:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common settings\n",
    "batch_size = 64\n",
    "action_bound = 1.\n",
    "tau = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "model_names = []\n",
    "window_length_lst = [3,7]\n",
    "predictor_type_lst = ['cnn']\n",
    "use_batch_norm = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1095, 4)\n",
      "(100, 730, 4)\n"
     ]
    }
   ],
   "source": [
    "nb_classes = len(target_stocks) + 1\n",
    "print(target_history.shape)\n",
    "print(testing_history.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start date: 2013-06-04\n",
      "1\n",
      "100\n",
      "0.0025\n"
     ]
    }
   ],
   "source": [
    "from environment.portfolio import PortfolioEnv\n",
    "env = PortfolioEnv(target_history, target_stocks, window_length = 1)\n",
    "print(env.window_length)\n",
    "print(env.num_stocks)\n",
    "print(env.sim.cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape training and testing data\n",
    "trainX = np.zeros(((target_history.shape[1]-env.window_length)*(env.num_stocks+1), 4, env.window_length + 1, env.num_stocks))\n",
    "testX = np.zeros(((testing_history.shape[1]-env.window_length)*(env.num_stocks+1), 4, env.window_length + 1, env.num_stocks))\n",
    "trainY = np.zeros(((target_history.shape[1]-env.window_length)*(env.num_stocks+1), env.num_stocks+1))\n",
    "testY = np.zeros(((testing_history.shape[1]-env.window_length)*(env.num_stocks+1), env.num_stocks+1))\n",
    "for i in range(target_history.shape[1]-env.window_length):\n",
    "    for stockHeld in range(env.num_stocks + 1):\n",
    "        for j in range(4):\n",
    "            for windowIndex in range(env.window_length):\n",
    "                for stock in range(env.num_stocks):\n",
    "                    trainX[i*(env.num_stocks+1)+stockHeld][j][windowIndex][stock] = target_history[stock][i+env.window_length-windowIndex-1][j]\n",
    "            if stockHeld > 0:\n",
    "                trainX[i*(env.num_stocks+1)+stockHeld][j][env.window_length][stockHeld-1] = 1\n",
    "\n",
    "for i in range(testing_history.shape[1]-env.window_length):\n",
    "    for stockHeld in range(1, env.num_stocks + 1):\n",
    "        for j in range(4):\n",
    "            for windowIndex in range(env.window_length):\n",
    "                for stock in range(env.num_stocks):\n",
    "                    testX[i*(env.num_stocks+1)+stockHeld][j][windowIndex][stock] = testing_history[stock][i+env.window_length-windowIndex-1][j]\n",
    "            if stockHeld > 0:\n",
    "                testX[i*(env.num_stocks+1)+stockHeld][j][env.window_length][stockHeld-1] = 1\n",
    "for i in range(target_history.shape[1]-env.window_length):\n",
    "    for stockHeld in range(env.num_stocks+1):\n",
    "        bestRate = 1.0\n",
    "        bestStock = -1\n",
    "        for stock in range(env.num_stocks):\n",
    "            trading_cost = env.sim.cost\n",
    "            if stockHeld-1 == stock:\n",
    "                trading_cost = 0\n",
    "            # print(trainX[i*(env.num_stocks+1) + stockHeld][3][0][stock], target_history[stock][i+env.window_length-1][3])\n",
    "            rate = target_history[stock][i+env.window_length-1][3]/target_history[stock][i+env.window_length-1][0] - trading_cost\n",
    "            if rate > bestRate:\n",
    "                bestRate = rate\n",
    "                bestStock = stock\n",
    "        trainY[i*(env.num_stocks+1) + stockHeld][bestStock+1] = 1\n",
    "for i in range(testing_history.shape[1]-env.window_length):\n",
    "    for stockHeld in range(env.num_stocks+1):\n",
    "        bestRate = 1.0\n",
    "        bestStock = -1\n",
    "        for stock in range(env.num_stocks):\n",
    "            trading_cost = env.sim.cost\n",
    "            if stockHeld-1 == stock:\n",
    "                trading_cost = 0\n",
    "            rate = testing_history[stock][i+env.window_length-1][3]/testing_history[stock][i+env.window_length-1][0] - trading_cost\n",
    "            if rate > bestRate:\n",
    "                bestRate = rate\n",
    "                bestStock = stock\n",
    "        testY[i*(env.num_stocks+1) + stockHeld][bestStock+1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built model from scratch\n"
     ]
    }
   ],
   "source": [
    "from model.supervised.cnn import StockCNN\n",
    "# instantiate CNN model\n",
    "cnn_model = StockCNN(nb_classes=100, window_length=4)\n",
    "cnn_model.build_model(load_weights=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_4_input to have shape (101, 4, 1) but got array with shape (101, 7, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-a4c5500daa4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# starts to train the model, hopefully it would work\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/School/Projects/summer2019/sum19/drl/src/model/supervised/cnn.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X_train, Y_train, X_val, Y_val, verbose)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mcontinue_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             self.model.fit(X_train, Y_train, batch_size=128, epochs=10, validation_data=(X_val, Y_val),\n\u001b[0;32m---> 63\u001b[0;31m                            shuffle=True, verbose=verbose)\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0msave_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Type True to save weights\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected conv2d_4_input to have shape (101, 4, 1) but got array with shape (101, 7, 1)"
     ]
    }
   ],
   "source": [
    "# starts to train the model, hopefully it would work\n",
    "cnn_model.train(trainX, trainY, testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common settings\n",
    "batch_size = 64\n",
    "action_bound = 1.\n",
    "tau = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "model_names = []\n",
    "window_length_lst = [3,7]\n",
    "predictor_type_lst = ['cnn']\n",
    "use_batch_norm = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1095, 4)\n",
      "(100, 730, 4)\n"
     ]
    }
   ],
   "source": [
    "nb_classes = len(target_stocks) + 1\n",
    "print(target_history.shape)\n",
    "print(testing_history.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start date: 2013-03-02\n"
     ]
    }
   ],
   "source": [
    "from environment.portfolio import PortfolioEnv, MultiActionPortfolioEnv\n",
    "env = PortfolioEnv(target_history, target_stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model from scratch\n",
      "Build model from scratch\n"
     ]
    }
   ],
   "source": [
    "# instantiate environment, 100 stocks, with trading cost, window_length 3, start_date sample each time\n",
    "# load weights = FALSE\n",
    "for window_length in window_length_lst:\n",
    "    for predictor_type in predictor_type_lst:\n",
    "        name = 'DDPG_window_{}_predictor_{}'.format(window_length, predictor_type)\n",
    "        model_names.append(name)\n",
    "        tf.reset_default_graph()\n",
    "        sess = tf.Session()\n",
    "        tflearn.config.init_training_mode()\n",
    "        action_dim = [nb_classes]\n",
    "        state_dim = [nb_classes, window_length]\n",
    "        variable_scope = get_variable_scope(window_length, predictor_type, use_batch_norm)\n",
    "        with tf.variable_scope(variable_scope):\n",
    "            actor = StockActor(sess, state_dim, action_dim, action_bound, 1e-4, tau, batch_size, predictor_type, \n",
    "                               use_batch_norm)\n",
    "            critic = StockCritic(sess=sess, state_dim=state_dim, action_dim=action_dim, tau=1e-3,\n",
    "                                 learning_rate=1e-3, num_actor_vars=actor.get_num_trainable_vars(), \n",
    "                                 predictor_type=predictor_type, use_batch_norm=use_batch_norm)\n",
    "            actor_noise = OrnsteinUhlenbeckActionNoise(mu=np.zeros(action_dim))\n",
    "\n",
    "            model_save_path = get_model_path(window_length, predictor_type, use_batch_norm)\n",
    "            summary_path = get_result_path(window_length, predictor_type, use_batch_norm)\n",
    "\n",
    "            ddpg_model = DDPG(env, sess, actor, critic, actor_noise, obs_normalizer=obs_normalizer,\n",
    "                              config_file='config/stock.json', model_save_path=model_save_path,\n",
    "                              summary_path=summary_path)\n",
    "            ddpg_model.initialize(load_weights=False, verbose=False)\n",
    "            models.append(ddpg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Issue encountered when serializing data_preprocessing.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'NoneType' object has no attribute 'name'\n",
      "WARNING:tensorflow:Issue encountered when serializing data_augmentation.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'NoneType' object has no attribute 'name'\n",
      "Episode: 0, Reward: 0.89, Qmax: 0.0190\n",
      "Episode: 1, Reward: 0.97, Qmax: 0.0207\n",
      "Episode: 2, Reward: 0.61, Qmax: 0.0188\n",
      "Episode: 3, Reward: 0.45, Qmax: 0.0174\n",
      "Episode: 4, Reward: 0.59, Qmax: 0.0172\n",
      "Episode: 5, Reward: 0.48, Qmax: 0.0174\n",
      "Episode: 6, Reward: 0.87, Qmax: 0.0181\n",
      "Episode: 7, Reward: 0.66, Qmax: 0.0179\n",
      "Episode: 8, Reward: 0.51, Qmax: 0.0174\n",
      "Episode: 9, Reward: 0.47, Qmax: 0.0185\n",
      "Episode: 10, Reward: 0.75, Qmax: 0.0206\n",
      "Episode: 11, Reward: 0.72, Qmax: 0.0226\n",
      "Episode: 12, Reward: 0.84, Qmax: 0.0239\n",
      "Episode: 13, Reward: 0.47, Qmax: 0.0241\n",
      "Episode: 14, Reward: 0.65, Qmax: 0.0259\n",
      "Episode: 15, Reward: 0.61, Qmax: 0.0274\n",
      "Episode: 16, Reward: 0.67, Qmax: 0.0292\n",
      "Episode: 17, Reward: 0.57, Qmax: 0.0297\n",
      "Episode: 18, Reward: 0.51, Qmax: 0.0319\n",
      "Episode: 19, Reward: 0.42, Qmax: 0.0336\n",
      "Episode: 20, Reward: 0.53, Qmax: 0.0343\n",
      "Episode: 21, Reward: 0.68, Qmax: 0.0360\n",
      "Episode: 22, Reward: 0.48, Qmax: 0.0367\n",
      "Episode: 23, Reward: 0.84, Qmax: 0.0390\n",
      "Episode: 24, Reward: 0.56, Qmax: 0.0403\n",
      "Episode: 25, Reward: 0.70, Qmax: 0.0411\n",
      "Episode: 26, Reward: 0.72, Qmax: 0.0427\n",
      "Episode: 27, Reward: 0.85, Qmax: 0.0437\n",
      "Episode: 28, Reward: 0.56, Qmax: 0.0454\n",
      "Episode: 29, Reward: 0.62, Qmax: 0.0467\n",
      "Episode: 30, Reward: 0.55, Qmax: 0.0473\n",
      "Episode: 31, Reward: 0.82, Qmax: 0.0489\n",
      "Episode: 32, Reward: 0.52, Qmax: 0.0502\n",
      "Episode: 33, Reward: 0.58, Qmax: 0.0510\n",
      "Episode: 34, Reward: 0.49, Qmax: 0.0520\n",
      "Episode: 35, Reward: 0.79, Qmax: 0.0539\n",
      "Episode: 36, Reward: 0.40, Qmax: 0.0549\n",
      "Episode: 37, Reward: 0.52, Qmax: 0.0564\n",
      "Episode: 38, Reward: 0.60, Qmax: 0.0577\n",
      "Episode: 39, Reward: 0.73, Qmax: 0.0594\n",
      "Episode: 40, Reward: 0.50, Qmax: 0.0598\n",
      "Episode: 41, Reward: 0.62, Qmax: 0.0612\n",
      "Episode: 42, Reward: 0.92, Qmax: 0.0619\n",
      "Episode: 43, Reward: 0.82, Qmax: 0.0631\n",
      "Episode: 44, Reward: 0.60, Qmax: 0.0650\n",
      "Episode: 45, Reward: 0.57, Qmax: 0.0650\n",
      "Episode: 46, Reward: 0.65, Qmax: 0.0662\n",
      "Episode: 47, Reward: 0.55, Qmax: 0.0668\n",
      "Episode: 48, Reward: 0.42, Qmax: 0.0668\n",
      "Episode: 49, Reward: 0.45, Qmax: 0.0685\n",
      "Episode: 50, Reward: 0.55, Qmax: 0.0684\n",
      "Episode: 51, Reward: 0.68, Qmax: 0.0686\n",
      "Episode: 52, Reward: 0.60, Qmax: 0.0697\n",
      "Episode: 53, Reward: 0.34, Qmax: 0.0699\n",
      "Episode: 54, Reward: 0.31, Qmax: 0.0708\n",
      "Episode: 55, Reward: 0.45, Qmax: 0.0720\n",
      "Episode: 56, Reward: 0.88, Qmax: 0.0737\n",
      "Episode: 57, Reward: 1.29, Qmax: 0.0741\n",
      "Episode: 58, Reward: 0.74, Qmax: 0.0741\n",
      "Episode: 59, Reward: 0.75, Qmax: 0.0761\n",
      "Episode: 60, Reward: 1.03, Qmax: 0.0774\n",
      "Episode: 61, Reward: 0.53, Qmax: 0.0775\n",
      "Episode: 62, Reward: 0.60, Qmax: 0.0796\n",
      "Episode: 63, Reward: 0.85, Qmax: 0.0792\n",
      "Episode: 64, Reward: 0.83, Qmax: 0.0811\n",
      "Episode: 65, Reward: 0.61, Qmax: 0.0826\n",
      "Episode: 66, Reward: 0.47, Qmax: 0.0837\n",
      "Episode: 67, Reward: 0.57, Qmax: 0.0840\n",
      "Episode: 68, Reward: 0.56, Qmax: 0.0858\n",
      "Episode: 69, Reward: 0.66, Qmax: 0.0859\n",
      "Episode: 70, Reward: 0.69, Qmax: 0.0869\n",
      "Episode: 71, Reward: 0.52, Qmax: 0.0884\n",
      "Episode: 72, Reward: 0.38, Qmax: 0.0897\n",
      "Episode: 73, Reward: 0.61, Qmax: 0.0906\n",
      "Episode: 74, Reward: 0.88, Qmax: 0.0917\n",
      "Episode: 75, Reward: 0.48, Qmax: 0.0934\n",
      "Episode: 76, Reward: 0.72, Qmax: 0.0939\n",
      "Episode: 77, Reward: 0.54, Qmax: 0.0945\n",
      "Episode: 78, Reward: 0.51, Qmax: 0.0955\n",
      "Episode: 79, Reward: 0.81, Qmax: 0.0960\n",
      "Episode: 80, Reward: 0.66, Qmax: 0.0978\n",
      "Episode: 81, Reward: 0.78, Qmax: 0.0971\n",
      "Episode: 82, Reward: 0.59, Qmax: 0.0983\n",
      "Episode: 83, Reward: 0.48, Qmax: 0.0989\n",
      "Episode: 84, Reward: 0.44, Qmax: 0.0999\n",
      "Episode: 85, Reward: 0.53, Qmax: 0.1008\n",
      "Episode: 86, Reward: 0.57, Qmax: 0.1014\n",
      "Episode: 87, Reward: 0.49, Qmax: 0.1014\n",
      "Episode: 88, Reward: 0.61, Qmax: 0.1018\n",
      "Episode: 89, Reward: 0.62, Qmax: 0.1031\n",
      "Episode: 90, Reward: 0.60, Qmax: 0.1036\n",
      "Episode: 91, Reward: 0.51, Qmax: 0.1036\n",
      "Episode: 92, Reward: 0.52, Qmax: 0.1047\n",
      "Episode: 93, Reward: 0.49, Qmax: 0.1053\n",
      "Episode: 94, Reward: 0.67, Qmax: 0.1069\n",
      "Episode: 95, Reward: 0.56, Qmax: 0.1072\n",
      "Episode: 96, Reward: 0.65, Qmax: 0.1074\n",
      "Episode: 97, Reward: 0.80, Qmax: 0.1093\n",
      "Episode: 98, Reward: 0.53, Qmax: 0.1102\n",
      "Episode: 99, Reward: 0.52, Qmax: 0.1101\n",
      "Episode: 100, Reward: 0.48, Qmax: 0.1111\n",
      "Episode: 101, Reward: 0.76, Qmax: 0.1116\n",
      "Episode: 102, Reward: 0.55, Qmax: 0.1111\n",
      "Episode: 103, Reward: 0.45, Qmax: 0.1113\n",
      "Episode: 104, Reward: 0.93, Qmax: 0.1126\n",
      "Episode: 105, Reward: 0.96, Qmax: 0.1124\n",
      "Episode: 106, Reward: 0.76, Qmax: 0.1131\n",
      "Episode: 107, Reward: 0.47, Qmax: 0.1141\n",
      "Episode: 108, Reward: 0.46, Qmax: 0.1145\n",
      "Episode: 109, Reward: 0.41, Qmax: 0.1151\n",
      "Episode: 110, Reward: 0.62, Qmax: 0.1154\n",
      "Episode: 111, Reward: 0.48, Qmax: 0.1176\n",
      "Episode: 112, Reward: 0.47, Qmax: 0.1176\n",
      "Episode: 113, Reward: 0.48, Qmax: 0.1184\n",
      "Episode: 114, Reward: 0.70, Qmax: 0.1186\n",
      "Episode: 115, Reward: 0.66, Qmax: 0.1193\n",
      "Episode: 116, Reward: 0.96, Qmax: 0.1206\n",
      "Episode: 117, Reward: 0.49, Qmax: 0.1211\n",
      "Episode: 118, Reward: 0.58, Qmax: 0.1217\n",
      "Episode: 119, Reward: 0.46, Qmax: 0.1224\n",
      "Episode: 120, Reward: 0.79, Qmax: 0.1234\n",
      "Episode: 121, Reward: 0.80, Qmax: 0.1231\n",
      "Episode: 122, Reward: 0.53, Qmax: 0.1239\n",
      "Episode: 123, Reward: 0.75, Qmax: 0.1247\n",
      "Episode: 124, Reward: 0.76, Qmax: 0.1261\n",
      "Episode: 125, Reward: 1.03, Qmax: 0.1261\n",
      "Episode: 126, Reward: 0.69, Qmax: 0.1260\n",
      "Episode: 127, Reward: 0.62, Qmax: 0.1265\n",
      "Episode: 128, Reward: 0.57, Qmax: 0.1275\n",
      "Episode: 129, Reward: 0.48, Qmax: 0.1279\n",
      "Episode: 130, Reward: 0.43, Qmax: 0.1274\n",
      "Episode: 131, Reward: 0.58, Qmax: 0.1293\n",
      "Episode: 132, Reward: 0.85, Qmax: 0.1293\n",
      "Episode: 133, Reward: 0.58, Qmax: 0.1295\n",
      "Episode: 134, Reward: 0.43, Qmax: 0.1309\n",
      "Episode: 135, Reward: 0.43, Qmax: 0.1306\n",
      "Episode: 136, Reward: 0.96, Qmax: 0.1316\n",
      "Episode: 137, Reward: 1.19, Qmax: 0.1314\n",
      "Episode: 138, Reward: 0.70, Qmax: 0.1317\n",
      "Episode: 139, Reward: 0.49, Qmax: 0.1328\n",
      "Episode: 140, Reward: 0.33, Qmax: 0.1324\n",
      "Episode: 141, Reward: 0.54, Qmax: 0.1327\n",
      "Episode: 142, Reward: 0.42, Qmax: 0.1323\n",
      "Episode: 143, Reward: 0.66, Qmax: 0.1338\n",
      "Episode: 144, Reward: 0.56, Qmax: 0.1335\n",
      "Episode: 145, Reward: 0.51, Qmax: 0.1339\n",
      "Episode: 146, Reward: 0.81, Qmax: 0.1340\n",
      "Episode: 147, Reward: 0.95, Qmax: 0.1354\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-c45d8f1d51d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mddpg_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/School/Projects/summer2019/sum19/drl/src/model/ddpg/ddpg.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, save_every_episode, verbose, debug)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                     \u001b[0;31m# batch update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                     \u001b[0ms_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m                     \u001b[0;31m# Calculate targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                     \u001b[0mtarget_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms2_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms2_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/School/Projects/summer2019/sum19/drl/src/model/ddpg/replay_buffer.py\u001b[0m in \u001b[0;36msample_batch\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0ms_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0ma_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mr_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ddpg_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
